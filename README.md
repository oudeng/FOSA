# FOSA: Full Information Maximum Likelihood (FIML) Optimized Self-Attention Imputation for Missing Data

## What's FOSA?
An innovative approach that amalgamates the strengths of Full Information Maximum Likelihood (FIML) estimation with the capabilities of self-attention neural networks. 
[Link to the PDF](Fig/FOSA_framework.pdf)

## Why FOSA?
Our comprehensive experiments on both simulated and real-world datasets underscore FOSAâ€™s pronounced advantages over traditional FIML techniques, encapsulating facets of accuracy, computational efficiency, and adaptability to diverse data structures.

## FOSA paper
In the folder **/paper**, or see it at arXiv: https://arxiv.org/submit/5075308

## FOSA code
In the folder **/code**.
